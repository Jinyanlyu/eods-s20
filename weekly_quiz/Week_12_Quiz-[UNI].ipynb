{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12 Quiz\n",
    "\n",
    "## [Name] - [UNI]\n",
    "\n",
    "### Due Sun May 10, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this quiz we'll practice using SQL to extract and transform some US State population data.\n",
    "\n",
    "We'll use pandasql to execute SQL on pandas dataframes.\n",
    "To do this we first need to install pandasql in our virtual environment.\n",
    "\n",
    "From the command line, run:<br>\n",
    "    `$ conda install -n eods-s20 pandasql`\n",
    "\n",
    "If for some reason you can't get this install or work, please just take a shot at what you think the SQL should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first need to run: conda install -n eods-s20 pandasql\n",
    "from pandasql import sqldf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up pysqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use sqldf to query our pandas dataframes using SQL commands\n",
    "\n",
    "# sqldf takes two arguments, the SQL query and the environment to execute in.\n",
    "# In this case the environment is always globals()\n",
    "\n",
    "# Setting up a simple helper function so we don't have to keep typing the environment.\n",
    "pysqldf = lambda query: sqldf(query,globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load state population data\n",
    "state_population = pd.read_csv('../data/state-population.csv')\n",
    "state_population = state_population.rename({'state/region':'abbreviation'},axis=1)\n",
    "\n",
    "# Load state area data\n",
    "state_areas = pd.read_csv('../data/state-areas.csv')\n",
    "state_areas = state_areas.rename({'area (sq. mi)':'area'},axis=1)\n",
    "\n",
    "# Load state abbreviation data\n",
    "state_abbrevs = pd.read_csv('../data/state-abbrevs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SQL to print out:\n",
    "#    all columns from table state_areas limited to the first 3 rows\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SQL to print out:\n",
    "#    columns state and area from table state_areas for rows with state starting with 'Mi'\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SQL to print out:\n",
    "#    columns state and area from table state_areas \n",
    "#    for rows with state starting with 'Mi' and area greater than 80000\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SQL to print out:\n",
    "#    the count of rows (aliased as num_states) from table state_areas where area greater than 100000\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write SQL to print out:\n",
    "#    all columns from table state_population limited to the first 3 rows\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_population.year.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that there is more than one row per abbreviation:\n",
    "#    there are different age groups and different years\n",
    "# For all rows with age='total', we'd like to find the average population across years for each abbreviation\n",
    "\n",
    "# Write SQL to print out:\n",
    "#    columns abbreviation and average of population (aliased as avg_population) from table state_population \n",
    "#    for rows where ages is 'total'\n",
    "#    limit to the first 3 rows\n",
    "# HINTS:\n",
    "#    you'll need to to GROUP BY abbreviation\n",
    "#    the sqlite command for taking a mean is AVG()\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'd like to divide this avg_population that we found by area.\n",
    "# Since state_population and state_area don't share any columns, we'll need to join them using state_abbrevs\n",
    "\n",
    "# Write SQL to print out:\n",
    "#    all columns in the first 3 rows of table state_abbrevs\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll first join state_areas with state_abbrevs.\n",
    "#    Each table has a column 'state' so that is what we'll use to join on.\n",
    "#    We'll use the default JOIN (INNER).\n",
    "\n",
    "# Write SQL to print out:\n",
    "#    state, area, and abbreviation from state_areas \n",
    "#    joined with state_abbrevs on state in both tables\n",
    "#    limited to the first 3 rows\n",
    "# HINTS:\n",
    "#    use whatever aliases (AS) for your tables as seems appropriate\n",
    "#    prepend the column names with table aliases to clarify where columns are coming from\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll join matching rows from state_population to get population data.\n",
    "# We'll limit our query to rows with ages = 'total' and year = '2012'.\n",
    "# We'll continue to use the default JOIN (INNER).\n",
    "\n",
    "# Write SQL to print out:\n",
    "#    state, area, abbreviation and population \n",
    "#    from state_areas \n",
    "#    joined with state_abbrevs on the state column\n",
    "#    joined with state_population on the abbreviations column\n",
    "#    where state_population ages = 'total' and state_population = 2012\n",
    "#    limited to first 3 rows\n",
    "# HINTS:\n",
    "#    use whatever aliases (AS) for your tables as seems appropriate\n",
    "#    prepend the column names with table aliases to clarify where columns are coming from\n",
    "\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this last query, we'll use a subquery to calculate avg_population divided by area for each state\n",
    "#    and print out the top 3 states sorted by this value.\n",
    "\n",
    "# Write SQL to print out:\n",
    "#    state, avg_population / area AS avg_pop_by_area \n",
    "#    from state_areas\n",
    "#    joined with state_abbrevs on the state column \n",
    "#    joined with (the subquery containing the SQL we used above to \n",
    "#        calculate avg_population, without the limit command) joined on abbreviation\n",
    "#    order by avg_pop_by_area descending\n",
    "#    limit to the first 3 rows\n",
    "# HINTS:\n",
    "#    remember to wrap the subquery in parenthesis and give the subquery an alias\n",
    "#    prepend the column names with table aliases to clarify where columns are coming from\n",
    "\n",
    "sql = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "pysqldf(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional:\n",
    "\n",
    "# Feel free to experiment with additional SQL calls. \n",
    "# For example, state_population contains more regions than there are states in state_areas\n",
    "#     so different join types (left, right) will give different results\n",
    "\n",
    "# Or, as a challenge: find states with the largest change in population_by_area between 1990 and 2013.\n",
    "# Create a dataframe which can be used to \n",
    "#    plot a line from the population_by_area in 1990 to 2013 for the top 10 countries, ordered by this difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s20",
   "language": "python",
   "name": "eods-s20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
